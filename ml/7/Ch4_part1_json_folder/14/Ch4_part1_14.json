{"page_id": 14, "full_text": {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_full_audio_14.mp3", "full_text": "Characteristics of k-NN Classifiers (1/3)\n1. They are examples of instance-based learning\n\u2013 Do not build a global model, but use training instances (i.e., model-free)\n\u2013 Require an appropriate proximity measure to determine the similarity \nbetween instances (e.g., the similarity between medical prescriptions)\n2. Although they do not require model building, classifying a test \ninstance can be quite expensive\n\u2013 Because we need to compute the similarity individually between the test \nand training instances\n3. They make predictions based on local information\n\u2013 By contrast, decision trees find a global model that fits the entire data\n\u2013 As a result, k-NN classifiers are quite susceptible to noise\n14\n"}, "text": [{"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_1.mp3", "font_size": 32, "text": "Characteristics of k-NN Classifiers (1/3)\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_2.mp3", "font_size": 24, "text": "1. They are examples of instance-based learning\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_3.mp3", "font_size": 20, "text": "\u2013 Do not build a global model, but use training instances (i.e., model-free)\n\u2013 Require an appropriate proximity measure to determine the similarity \nbetween instances (e.g., the similarity between medical prescriptions)\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_4.mp3", "font_size": 24, "text": "2. Although they do not require model building, classifying a test \ninstance can be quite expensive\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_5.mp3", "font_size": 20, "text": "\u2013 Because we need to compute the similarity individually between the test \nand training instances\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_6.mp3", "font_size": 24, "text": "3. They make predictions based on local information\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_7.mp3", "font_size": 20, "text": "\u2013 By contrast, decision trees find a global model that fits the entire data\n\u2013 As a result, k-NN classifiers are quite susceptible to noise\n"}, {"audio_url": "https://storage.googleapis.com/cloud_storage_leturn/Ch4_part1.pdf/Ch4_part1_audio_folder/14/Ch4_part1_audio_14_8.mp3", "font_size": 14, "text": "14\n"}], "image": []}