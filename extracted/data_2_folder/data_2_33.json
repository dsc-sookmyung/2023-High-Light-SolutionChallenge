{
	"page_id": 33,
	"full_text": {
		"audio_url": "",
		"full_text": "3. Dimensionality Reduction\n▪ The process of reducing the number of attributes in the data set\n– Dimensionality = the number of attributes\n▪ Key benefits\n① Many data mining algorithms work better if the dimensionality is lower\n• Partly because irrelevant features are eliminated and noise is reduced\n• Partly because the curse of dimensionality\n② A more understandable model can be obtained\n• Because the model involves fewer attributes\n• (ex) y = x1 + 5.1x2 + 4.2x3 + 8.7x4 + 7.4x5 + 2.9x6 + 10x7 → y = z1 + 7.2z2\n33\n"
	},
	"text": [
		{
			"audio_url": "",
			"font_size": 32,
			"text": "3. Dimensionality Reduction\n"
		},
		{
			"audio_url": "",
			"font_size": 24,
			"text": "▪ The process of reducing the number of attributes in the data set\n"
		},
		{
			"audio_url": "",
			"font_size": 20,
			"text": "– Dimensionality = the number of attributes\n"
		},
		{
			"audio_url": "",
			"font_size": 24,
			"text": "▪ Key benefits\n"
		},
		{
			"audio_url": "",
			"font_size": 20,
			"text": "① Many data mining algorithms work better if the dimensionality is lower\n"
		},
		{
			"audio_url": "",
			"font_size": 18,
			"text": "• Partly because irrelevant features are eliminated and noise is reduced\n• Partly because the curse of dimensionality\n"
		},
		{
			"audio_url": "",
			"font_size": 20,
			"text": "② A more understandable model can be obtained\n"
		},
		{
			"audio_url": "",
			"font_size": 18,
			"text": "• Because the model involves fewer attributes\n"
		},
		{
			"audio_url": "",
			"font_size": 12,
			"text": "• (ex) y = x1 + 5.1x2 + 4.2x3 + 8.7x4 + 7.4x5 + 2.9x6 + 10x7 → y = z1 + 7.2z2\n"
		},
		{
			"audio_url": "",
			"font_size": 14,
			"text": "33\n"
		}
	],
	"image": {
		"img_idx": 1,
		"audio_url": "",
		"img_url": ""
	}
}